{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CI/CD Pipeline and Tooling Tutorials","text":"<p>This website contains tutorials on how to develop CI/CD pipelines and how to configure a development environment for working with CI/CD pipelines.</p>"},{"location":"#what-are-cicd-pipelines","title":"What are CI/CD pipelines?","text":"<p>CI/CD refers to the combination of Continuous Integration (CI) and Continuous Delivery (CD) practices. Both of these practices aim to increase the frequency at which changes are released. The increase in release frequency is often enabled by automation pipelines.</p>"},{"location":"#continuous-integration","title":"Continuous Integration","text":"<p>In Continuous Integration, code changes are merged from development or feature branches to the main branch as often as possible. This provides more frequent feedback to the developers and should lead into smaller individual changes that are easier to integrate into the main branch.</p> <p>Continuous Integration is often supported by CI pipeline that automatically validates the changes to be merged into the main branch. These automatic validation can include, for example, static code analysis and automated tests. The CI pipelines are usually automatically triggered by an event in a version control system. For example, a CI pipeline could be automatically triggered when a pull request is created or updated.</p> <p>In addition to automated validations done by the CI pipeline, continuous integration processes may include manual validations. For example, code review done by another developer might be required in order to be able to merge the change.</p>"},{"location":"#continuous-delivery","title":"Continuous Delivery","text":"<p>In Continuous Delivery, code changes are continuously built and delivered to a release target. For example, a web application could be updated after each new change on the main branch. Similarly than with Continuous Integration, the goal is to get more frequent feedback on code changes. Delivering changes more frequently should lead into a better delivery routine and more well defined delivery process.</p> <p>Continuous Delivery is often implemented with a CD pipeline. The CD pipeline could, for example, build the main branch after a code change was merged in and deploy the build result into a test or staging environment. The CD pipeline might also have steps that wait for human approval before they are executed. For example, deployment to a production environment might require human approval.</p> <p>The CI and CD pipelines are often tightly integrated with each other. Delivery is usually done after validating the code change and more complex validation might require the code change to be delivered into a test environment.</p>"},{"location":"#installing-docker","title":"Installing Docker","text":"<p>Many of the tutorials provided on this website require Docker and Docker Compose to be installed on your development environment.</p> <p>See Get Docker for official installation instructions. If you use Docker a lot on a Mac or Windows system, the recommended Docker Desktop is likely a good option for you. Note that, since January 2022, it has required paid subscription, if used for commercial development.</p> <p>Alternatively, Windows users can install Docker on top of WSL2. For Mac users there are alternatives, such as Colima, available.</p>"},{"location":"assets/","title":"Assets","text":""},{"location":"assets/#icon","title":"Icon","text":""},{"location":"assets/#48px","title":"48px","text":"<p>Take a screeshot of this icon with Firefox consoles <code>:screenshot</code> command:</p> <pre><code>:screenshot --selector \".icon.size-48x48\" --dpr 1 --filename \"favicon.png\"\n</code></pre>"},{"location":"assets/#512px","title":"512px","text":"<p>Take a screeshot of this icon with Firefox consoles <code>:screenshot</code> command:</p> <pre><code>:screenshot --selector \".icon.size-512x512\" --dpr 1 --filename \"logo-512.png\"\n</code></pre>"},{"location":"tutorials/docker/docker-on-wsl/","title":"Install Docker on Windows Subsystem for Linux","text":"<p>If you do not already have Windows Subsystem for Linux (WSL) installed, see Install Linux on Windows with WSL for instructions.</p> <p>This document describes how to configure WSL 2, install recent version of Ubuntu (24.04 LTS), and install Docker as well as Docker compose.</p>"},{"location":"tutorials/docker/docker-on-wsl/#configure-wsl-settings","title":"Configure WSL settings","text":"<p>Open PowerShell and check current WSL status by running <code>wsl --status</code>.</p> <pre><code>wsl --status\n</code></pre> <p>If default version is not 2, run <code>wsl --set-default-version 2</code>. This enables more recent, virtual machine based WSL, that is required for us to be able to run Docker daemon in the WSL.</p> <pre><code>wsl --set-default-version 2\n</code></pre> <p>If output indicates any problems with WSL 2 Kernel, such as <code>The WSL 2 kernel file is not found.</code>, run <code>wsl --update</code> and <code>wsl --shutdown</code>, as suggested. These command might require admin priviledges. To obtain these, find PowerShell, right click it, and select Run as System Administrator.</p> <pre><code>wsl --update\nwsl --shutdown\n</code></pre> <p>Run <code>wsl --status</code> again. The output should display 2 as default version, recent last update date, and kernel version.</p> <p>If you already have recent version of Ubuntu installed, ensure that it uses WSL 2 by running <code>wsl --list --verbose</code>. If necessary, use <code>wsl --set-version</code> to update your instance to use WSL 2. Skip next section.</p> <pre><code>wsl --list --verbose\nwsl --set-version \"YOUR_DISTRO_HERE\" 2\n</code></pre> WSL commands only output usage instructions <p>If the <code>wsl</code> command outputs usage instructions instead of the expected output regardless of given parameters, ensure that your system has following Windows features enabled:</p> <ul> <li>Windows Subsystem for Linux</li> <li>Virtual Machine Platform</li> <li>Hyper-V</li> </ul> <p>To do this, open the Turn Windows Features on or off dialog from Start menu, Settings, or Control Panel, and ensure that the features mentioned above are selected.</p>"},{"location":"tutorials/docker/docker-on-wsl/#install-recent-version-of-ubuntu","title":"Install recent version of Ubuntu","text":"<p>Install recent version of Ubuntu from either Microsoft Store or PowerShell. These instructions use Ubuntu 24.04. Other distributions might also work, if you know what you are doing.</p> PowerShellMicrosoft Store <p>If you want to install distro through the PowerShell, run <code>wsl --list --online</code> and follow the instructions:</p> <pre><code>wsl --list --online\nwsl --install -d Ubuntu-24.04\n</code></pre> <p>If you want to install distro through Microsoft Store: Open Microsoft Store, search for <code>Ubuntu 24</code>, select Ubuntu 24.04 LTS, and click Install.</p> <p>If not launched automatically, open the installed Ubuntu distro (e.g., by clicking it in the Start menu) and follow instruction in installation wizard. You will have to choose an username and a password to use in the WSL instance. To make your life easier, use only lowercase letters and numbers in your Linux username.</p>"},{"location":"tutorials/docker/docker-on-wsl/#install-docker","title":"Install Docker","text":"<p>Open Ubuntu you just installed and follow Install Docker Engine on Ubuntu instructions.</p> <p>tl;dr: Run the convenience script available in <code>get.docker.com</code>:</p> <pre><code>curl -fsSL https://get.docker.com -o get-docker.sh\nsudo sh get-docker.sh\n</code></pre> <p>Ignore the <code>WSL DETECTED: We recommend using Docker Desktop for Windows.</code> warning.</p> <p>To be able to run docker commands without <code>sudo</code>, add current user to <code>docker</code> group with <code>usermod</code>. Note that you might have to logout and login for the changes to take effect.</p> <pre><code>sudo usermod -aG docker $USER\n</code></pre>"},{"location":"tutorials/docker/docker-on-wsl/#configure-networking","title":"Configure networking","text":"<p>By default, WSL 2 uses local DNS server to reflect network settings, such as VPN, from the host Windows to WSL instances. The IP address of this DNS server might fall into IP range used by the Dockers default bridge network. In that case, containers will not be able to resolve domains.</p> <p>To configure working DNS inside containers you can either modify IP range used by Dockers default network or use public DNS. If you are working behind a corporate firewall, public DNS might not work.</p> Configure IP range for DockerUse public DNS in WSL 2 <p>To configure Docker to use IP ranges that wont overlap with DNS server configured by WSL, add following content to <code>/etc/docker/daemon.json</code>, for example, by opening it with <code>sudo nano /etc/docker/daemon.json</code>:</p> /etc/docker/daemon.json<pre><code>{\n  \"bip\": \"172.21.0.1/16\",\n  \"default-address-pools\": [\n    {\n      \"base\":\"172.22.0.0/16\",\n      \"size\":24\n    }\n  ]\n}\n</code></pre> <p>If you already have dockerd running, you have to restart it for the changes to take effect.</p> <pre><code>sudo service docker restart\n</code></pre> <p>If containers cannot resolve domains or have other issues with internet access with above configuration, ensure that the above networks do not overlap with network interface configured by WSL. To do this, run <code>ip a</code> or <code>ifconfig</code> command ( or <code>ipconfig</code> in powershell) and check the IP address assigned for <code>eth0</code> interface it output. If the second part of the IP address matches either IP block defined in the above configuration, change the value in <code>/etc/docker/daemon.json</code>. Any private IP v4 address block should work. You can use, for example, some blocks between <code>172.16.0.0/16</code> and <code>172.31.0.0/16</code>, i.e., change the second part of the IP address.</p> <p>To use public DNS, you must first disable WSL from automatically generating DNS settings to <code>/etc/resolv.conf</code>. To do this, add following rows to <code>/etc/wsl.conf</code> file in your WSL instance, for example, by editing (or creating) it with <code>sudo nano /etc/wsl.conf</code>:</p> /etc/wsl.conf<pre><code>[network]\ngenerateResolvConf = false\n</code></pre> <p>For the changes to take effect, restart WSL by running <code>wsl --shutdown</code> in powershell and launching WSL instance again.</p> <pre><code>wsl --shutdown\n</code></pre> <p>Finally, configure DNS server manually by creating <code>/etc/resolv.conf</code> with following content, for example by opening it with <code>sudo nano /etc/resolv.conf</code>:</p> /etc/resolv.conf<pre><code>nameserver 8.8.8.8\n</code></pre>"},{"location":"tutorials/docker/docker-on-wsl/#ensure-docker-daemon-is-running","title":"Ensure Docker daemon is running","text":"<p>Recent version of WSL enable systemd by default. In this case, Docker daemon should be started automatically when ever WSL is running. To verify Docker has been started, run the hello-world container:</p> <pre><code>docker run hello-world\n</code></pre> <p>If Docker was not started automatically, start <code>dockerd</code> as a background process by using <code>service</code> or, alternatively, start <code>dockerd</code> directly.</p> <pre><code>sudo service docker start\n</code></pre> <p>If <code>docker</code> commands print <code>Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?</code> error, run <code>sudo service docker status</code> command to check if <code>dockerd</code> is running and, if necessary, run <code>sudo service docker start</code> command to start the Docker service.</p> Launch docker with boot settings <p>If you are working on earlier version of Windows 11, you can use boot settings to start Docker daemon automatically on WSL instance startup. To do this, add following rows to <code>/etc/wsl.conf</code> file in your WSL instance, for example, by editing (or creating) it with <code>sudo nano /etc/wsl.conf</code>.</p> /etc/wsl.conf<pre><code>[boot]\ncommand = service docker start\n</code></pre> <p>Note that this should not be done if systemd is enabled.</p>"},{"location":"tutorials/docker/docker-on-wsl/#install-docker-compose","title":"Install Docker compose","text":"<p>Follow Install Docker Compose instructions for Linux.</p> <p>tl;dr: Install Docker Compose with the distros package manager:</p> <pre><code>sudo apt-get update\nsudo apt-get install docker-compose-plugin\n</code></pre>"},{"location":"tutorials/gitlab-ci/docker-hub-ratelimit/","title":"Docker-in-Docker service and Docker Hub ratelimit","text":"<p>The recommended way of running Docker commands in a GitLab CI Kubernets runner is to use a service to run Docker-in-Docker container (<code>docker:dind</code>). By default the <code>docker:dind</code> container pulls container images from Docker Hub without caching. This can cause problems as pulls from Docker Hub are rate-limited.</p> <p>This tutorial tests how <code>docker pull ubuntu:24.04</code> commands consume Docker Hub ratelimit and provides example on how to configure pull-through cache to an Kubernetes cluster working as a GitLab runner.</p>"},{"location":"tutorials/gitlab-ci/docker-hub-ratelimit/#how-to-check-if-docker-pull-commands-are-cached","title":"How to check if <code>docker pull</code> commands are cached","text":"<p>Create a new GitLab project with <code>.gitlab-ci.yml</code> and <code>scripts/check-docker-hub-ratelimit.sh</code> files.</p> <p>The <code>scripts/check-docker-hub-ratelimit.sh</code> script prints current Docker Hub ratelimit and also writes the result to a file if filename is given as first parameter. See Docker Hub usage and rate limits article in Docker documentation for more details.</p> scripts/check-docker-hub-ratelimit.sh<pre><code>#!/bin/sh -e\n\nfetch_ratelimit() {\n    curl -I -H \"Authorization: Bearer $1\" https://registry-1.docker.io/v2/ratelimitpreview/test/manifests/latest 2&gt;&amp;1 | grep -i ratelimit\n}\n\ntarget=$1\ntoken=$(curl -s \"https://auth.docker.io/token?service=registry.docker.io&amp;scope=repository:ratelimitpreview/test:pull\" | jq -r .token)\n\nif [ -n \"$target\" ]; then\n    fetch_ratelimit $token | tee $target;\nelse\n    fetch_ratelimit $token;\nfi\n</code></pre> <p>The pipeline defined by <code>.gitlab-ci.yml</code> tries to pull the same Docker image twice and checks if the rate limit headers are different after first and second pull.</p> .gitlab-ci.yml<pre><code>default:\n  image: docker:cli\n  services:\n    - name: \"docker:dind\"\n      command: [\"--tls=false\", \"--host=tcp://0.0.0.0:2375\"]\n\nvariables:\n  DOCKER_TLS_CERTDIR: \"\"\n  DOCKER_HOST: tcp://docker:2375\n\nstages:\n  - test\n\ntest-caching:\n  stage: test\n  before_script:\n    - apk add curl jq\n  script:\n    - docker pull ubuntu:24.04\n    - ./scripts/check-docker-hub-ratelimit.sh 1st.txt\n    - docker rmi ubuntu:24.04\n    - docker pull ubuntu:24.04\n    - ./scripts/check-docker-hub-ratelimit.sh 2nd.txt\n    - diff 1st.txt 2nd.txt\n</code></pre> <p>The pipeline should fail, if images are pulled directly from Docker Hub.</p>"},{"location":"tutorials/gitlab-ci/docker-hub-ratelimit/#how-to-setup-pull-through-cache-to-kubernetes-runner","title":"How to setup pull-through cache to Kubernetes runner","text":"<p>Manifests for configuring pull-through cache and configmap are available in the repository that provides this website.</p> <pre><code>git clone https://github.com/cicd-tutorials/cicd-tutorials.net.git\ncd docs/tutorials/gitlab-ci/docker-hub-ratelimit\n</code></pre> <p>Configure pull-through cache and configmap for GitLab runner by running <code>kubectl apply -f manifests/</code>.</p> <pre><code>kubectl apply -f manifests/\n</code></pre> <p>These manifests assume that GitLab runner is using gitlab-runner namespace. Edit the namespace value in docker-config.yaml if this is not the case.</p> <p>Modify the GitLab runner configuration so that the configmap defined in docker-config.yaml is mounted to all containers launched by the GitLab runner. Example of a full <code>values.yaml</code> help input file below.</p> <pre><code>gitlabUrl: # Your instance URL\nrbac: { create: true }\nrunnerToken: # Your runner token\nrunners:\n  config: |\n    [[runners]]\n      executor = \"kubernetes\"\n      [runners.kubernetes]\n        image = \"alpine:3.12\"\n        privileged = true\n        [[runners.kubernetes.volumes.config_map]]\n          name = \"dockerd-config\"\n          mount_path = \"/etc/docker/daemon.json\"\n          sub_path = \"daemon.json\"\n</code></pre>"},{"location":"tutorials/jenkins/ansible-kubernetes/","title":"Deploy application to Kubernetes with Ansible","text":"<p>This tutorial contains a pipeline that deploys an simple hello-world application to a Kubernetes cluster.</p>"},{"location":"tutorials/jenkins/ansible-kubernetes/#prerequisites","title":"Prerequisites","text":"<p>You will need a running Kubernetes cluster, that supports services with <code>LoadBalancer</code> type, and a kubeconfig file that can be used to deploy application (a deployment and a service) into the cluster.</p>"},{"location":"tutorials/jenkins/ansible-kubernetes/#preparing-the-jenkins-instance","title":"Preparing the Jenkins instance","text":"<p>The pipeline provided by this tutorial can be added to any Jenkins instance you have administrator access and can run pipeline stages with docker agent. For example, Jenkins configuration from Jenkins with access to hosts Docker engine tutorial can be used.</p> <p>We will use secret file to configure credentials for managing the target Kubernetes cluster. To create the secret file credential, open Global credentials from Jenkins credentials store from Manage Jenkins &gt; Manage Credentials and click Add Credentials from the left side menu.</p> <p>In the New credentials form:</p> <ol> <li>Select Secret file as the credential kind</li> <li>Upload your kubeconfig to the file input</li> <li>Configure ID for the credential. Jenkinsfile uses <code>kubeconfig</code> as the ID.</li> <li>(Optionally) add a description.</li> </ol>"},{"location":"tutorials/jenkins/ansible-kubernetes/#configure-the-pipeline","title":"Configure the pipeline","text":"<p>First, create a new pipeline via New Item button in the rigth side menu of the Jenkins dashboard. The name of the pipeline could be for example <code>Animals</code> and it should be an pipeline.</p> <p>In the configure pipeline view, scroll to the bottom and under Pipeline sub-header select <code>Pipeline script from SCM</code>. SCM type should be <code>Git</code> and Repository URL the url of this repository: <code>https://github.com/cicd-tutorials/cicd-tutorials.net.git</code>. Ensure that branch specifier includes <code>main</code> branch of the repository and modify the Script Path to be <code>docs/tutorials/jenkins/ansible-kubernetes/Jenkinsfile</code>.</p> <p>The pipeline deploys an example application to a Kubernetes cluster using Ansible playbook. The playbook selects a container image tag based on Jenkins build parameter.</p> Jenkinsfile<pre><code>String d = \"docs/tutorials/jenkins/ansible-kubernetes\"\n\npipeline {\n    agent any\n    parameters {\n        choice(name: 'ANIMAL', choices: ['cat', 'cow', 'dog', 'lion', 'pig'], description: 'Tag to use for deployment image')\n    }\n    stages {\n        stage(\"deploy\") {\n            agent {\n                dockerfile {\n                    dir \"$d\"\n                    reuseNode true\n                }\n            }\n            environment {\n                K8S_AUTH_KUBECONFIG = credentials('kubeconfig')\n                KUBECONFIG = credentials('kubeconfig')\n            }\n            steps {\n                sh \"\"\"\n                    ansible-playbook $d/deploy-to-kubernetes.yml --extra-vars \"animal=${params.ANIMAL}\"\n                    ./$d/wait-until-service-up.sh\n                \"\"\"\n            }\n        }\n    }\n}\n</code></pre> <p>After you have created the pipeline, try to execute it by clicking Build Now. The pipeline should have deployed the example application into the Kubernetes cluster with the default image tag (<code>cow</code>) defined in the deploy-to-kubernetes.yml Ansible playbook.</p> deploy-to-kubernetes.yml<pre><code>- name: Deploy and expose application\n  hosts: localhost\n  gather_facts: no\n  vars:\n    animal: cow\n  tasks:\n  - name: Create a deployment\n    kubernetes.core.k8s:\n      definition:\n        apiVersion: apps/v1\n        kind: Deployment\n        metadata:\n          labels:\n            app: animals\n          name: animals\n          namespace: default\n        spec:\n          replicas: 3\n          selector:\n            matchLabels:\n              app: animals\n          template:\n            metadata:\n              labels:\n                app: animals\n            spec:\n              containers:\n              - image: ghcr.io/cicd-tutorials/animals:{{ animal }}\n                name: animals\n  - name: Expose the deployment\n    kubernetes.core.k8s:\n      definition:\n        apiVersion: v1\n        kind: Service\n        metadata:\n          labels:\n            app: animals\n          name: animals\n          namespace: default\n        spec:\n          ports:\n          - port: 80\n            protocol: TCP\n            targetPort: 80\n          selector:\n            app: animals\n          type: LoadBalancer\n</code></pre> <p>After the Ansible playbook has been executed, the pipeline runs wait-until-service-up.sh script. The script waits until the load-balancer created by the Kubernetes service has reached running state and parses the URL where the example application is running.</p> <pre><code>#!/bin/sh -xe\n\n# Wait until hostname is available\nuntil kubectl get service animals -o json | jq -re .status.loadBalancer.ingress[0].hostname; do\n    sleep 15;\ndone;\n\n# Wait until animals application is up\nhostname=$(kubectl get service animals -o json | jq -re .status.loadBalancer.ingress[0].hostname)\nuntil curl -sSf $hostname; do\n    sleep 15;\ndone;\n\necho \"Load-balancer URL: $hostname\"\n</code></pre> <p>You can find the URL of the created load-balancer from the console output of the build. Open the application with your browser or user curl to see the application response.</p> <p>In addition, after the first execution Jenkins should have updated the project configuration to contain parameters defined in the pipeline and we can configure the image tag in Build with Parameters menu.</p>"},{"location":"tutorials/jenkins/build-status-pipelines/","title":"Build status pipelines and Job DSL","text":"<p>This tutorial contains pipelines to produce builds with success, unstable, failed, aborted, and not-built statuses as well as Job DSL script to create a folder with projects that have these five different statuses.</p>"},{"location":"tutorials/jenkins/build-status-pipelines/#preparing-the-jenkins-instance","title":"Preparing the Jenkins instance","text":"<p>The pipeline provided by this tutorial can be added to any Jenkins instance you have administrator access. For example, Jenkins configuration from Jenkins with access to hosts Docker engine tutorial can be used.</p> <p>In order to be able to run the seed project we will need Job DSL plugin. Install the plugin through Available tab in Manage Jenkins &gt; Manage Plugins.</p>"},{"location":"tutorials/jenkins/build-status-pipelines/#creating-and-running-the-seed-project","title":"Creating and running the seed project","text":"<p>To run the job DSL script, create a new pipeline with following script as an inline pipeline script and run the created pipeline.</p> <pre><code>node {\n    git branch: 'main', url: 'https://github.com/cicd-tutorials/cicd-tutorials.net.git'\n    jobDsl targets: 'docs/tutorials/jenkins/build-status-pipelines/jobs.groovy'\n}\n</code></pre> <p>The execution will likely fail with <code>ERROR: script not yet approved for use</code> message. To enable this script, navigate to Manage Jenkins &gt; In-process Script Approval, inspect the script, and click Approve. Then try to run the created seed project again. It should now succeed and list the created resources.</p> <p>The scripted pipeline listed above executes jobs.groovy script. This script creates five new pipelines and executes four of those.</p> jobs.groovy<pre><code>String d = \"docs/tutorials/jenkins/build-status-pipelines\"\n\nfolder('Status') {\n    description('Example pipelines to produce success, unstable, failed, aborted, and not-built statuses.')\n}\n\ndef statuses = ['Success', 'Unstable', 'Failed', 'Aborted']\nfor (status in statuses) {\n    def name = \"Status/${status}\"\n\n    pipelineJob(name) {\n        definition {\n            cps {\n                script(readFileFromWorkspace(\"$d/${status.toLowerCase()}.Jenkinsfile\"))\n                sandbox()\n            }\n        }\n    }\n    queue(name)\n}\n\npipelineJob('Status/Not built') {\n    definition {\n        cps {\n            script(readFileFromWorkspace(\"$d/success.Jenkinsfile\"))\n            sandbox()\n        }\n    }\n}\n</code></pre> <p>The four different pipeline scripts used to create the jobs are listed below. The final job, <code>Status/Not built</code>, uses the same script as <code>Status/Success</code>, but the build is not executed.</p> AbortedFailedSuccessUnstable <p>Defines a pipeline that has a three minute timeout and build step that takes more than three minutes.</p> aborted.Jenkinsfile<pre><code>pipeline {\n    agent any\n    options {\n        timeout(time: 3, unit: 'MINUTES')\n    }\n    stages {\n        stage('Sleep') {\n            steps {\n                sleep time: 5, unit: 'MINUTES'\n            }\n        }\n    }\n}\n</code></pre> <p>Defines a pipeline with single <code>sh</code> step that produces a non-zero exit code.</p> failed.Jenkinsfile<pre><code>pipeline {\n    agent any\n    stages {\n        stage('Fail on purpose') {\n            steps {\n                sh 'exit 1'\n            }\n        }\n    }\n}\n</code></pre> <p>Defines a pipeline with single succeeding <code>sh</code> step.</p> success.Jenkinsfile<pre><code>pipeline {\n    agent any\n    stages {\n        stage('Say hello') {\n            steps {\n                echo 'Hello!'\n            }\n        }\n    }\n}\n</code></pre> <p>Defines a pipeline with single <code>unstable</code> step.</p> unstable.Jenkinsfile<pre><code>pipeline {\n    agent any\n    stages {\n        stage('Set unstable') {\n            steps {\n                unstable 'Demo unstable usage'\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"tutorials/jenkins/jenkins-host-docker/","title":"Jenkins with access to hosts Docker engine","text":"<p>This tutorial provider Docker Compose configuration for running Jenkins inside a container with Docker client that controls host machines Docker engine using a socket. This works well in development environments as you can inspect containers created by Jenkins from the host system.</p> <p>Note that by default each of the example Docker Compose configurations will create their own volumes for the data. This might not be what you want, if you want to use configuration from Integrating Jenkins and SonarQube as well. In order to use the same volumes for every docker compose configuration, run docker compose with <code>-p</code> (or <code>--project-name</code>) option. This can also be done by setting <code>COMPOSE_PROJECT_NAME</code> environment variable:</p> <pre><code>export COMPOSE_PROJECT_NAME=jenkins\n</code></pre>"},{"location":"tutorials/jenkins/jenkins-host-docker/#jenkins-image-with-docker-client","title":"Jenkins image with Docker client","text":"<p>To be able run Docker commands from inside the Jenkins container, we will need to install the Docker client. This can be done with a suitable Dockerfile:</p> Dockerfile<pre><code>FROM jenkins/jenkins:lts-alpine\n\n# Change user to root in order to have permissions to install packages.\nUSER root\n\n# Only Docker client is required inside the Jenkins container as the host\n# systems Docker engine is used from inside the container.\nRUN apk add docker-cli\n\n# Note that the user is not switched back to jenkins here. This is to avoid\n# problems with docker socket permissions. Do not use root user in production.\n# Instead, match group IDs of docker groups in host and container and add\n# jenkins user to the docker group.\n</code></pre>"},{"location":"tutorials/jenkins/jenkins-host-docker/#jenkins-container-with-access-to-hosts-docker-engine","title":"Jenkins container with access to hosts Docker engine","text":"<p>When running Jenkins in a container, we will want to define ports and volumes. To do this, we will use a <code>docker-compose.yml</code> configuration:</p> docker-compose.yml<pre><code>services:\n  jenkins:\n    build: .\n    ports:\n      # Web user interface\n      - 8080:8080\n      # Java agents\n      - 50000:50000\n    volumes:\n      # Persistent volume for the Jenkins data\n      - \"jenkins.data:/var/jenkins_home\"\n      # Host systems docker socket\n      - \"/var/run/docker.sock:/var/run/docker.sock\"\n\nvolumes:\n  jenkins.data:\n</code></pre> <p>These files are available in the repository that provides this website. In order to run Jenkins container with Docker-in-Docker support, <code>cd</code> into <code>docs/tutorials/jenkins/jenkins-host-docker</code> directory and run <code>docker compose up</code>.</p> BackgroundForeground <p>To run the Jenkins container in the background, execute <code>docker compose up</code> command with <code>-d</code>/<code>--detach</code> flag:</p> <pre><code>cd docs/tutorials/jenkins/jenkins-host-docker\n\ndocker compose up --build --detach\n</code></pre> <p>This allows the Jenkins container to continue running even if you close the terminal session. Use <code>docker compose logs</code> command to see the logs.</p> <p>To run the Jenkins container in the foreground, execute <code>docker compose up</code> command without <code>-d</code>/<code>--detach</code> flag:</p> <pre><code>cd docs/tutorials/jenkins/jenkins-host-docker\n\ndocker compose up --build\n</code></pre> <p>You can now monitor the logs produced by the Jenkins container in your current shell. However, if you close the terminal session or send an interrupt signal (for example by pressing CTRL+C), the Jenkins container will be stopped.</p> <p>The initial admin password can be printed with <code>docker compose exec</code> command:</p> <pre><code>docker compose exec jenkins cat /var/jenkins_home/secrets/initialAdminPassword\n</code></pre> <p>In order to get started with Jenkins, the suggested plugins are often good a starting point. If you are planning to create pipeline projects with stages running in on-demand Docker containers, you will also need Docker Pipeline plugin. This can be installed through the Manage Jenkins &gt; Manage plugins menu.</p>"},{"location":"tutorials/jenkins/parallel-robot-pipeline/","title":"Parallel Robot Framework pipeline","text":"<p>This directory provides an tutorial of a Jenkins pipeline that executes Robot Framework automation tasks with docker agent in parallel stages as well as combines and stores the produced HTML/XML report files.</p>"},{"location":"tutorials/jenkins/parallel-robot-pipeline/#preparing-the-jenkins-instance","title":"Preparing the Jenkins instance","text":"<p>The pipeline provided by this tutorial can be added to any Jenkins instance you have administrator access and can run pipeline stages with docker agent. For example, Jenkins configuration from Jenkins with access to hosts Docker engine tutorial can be used.</p> <p>In order to be able to run the pipeline we will need Docker Pipeline and Robot Framework plugins. Install these plugins through Available tab in Manage Jenkins &gt; Manage Plugins and restart the Jenkins instance after these plugins have been installed. The restart can be done, for example, from the plugins page or by restarting the container with <code>docker compose down</code> and <code>docker compose up</code>.</p>"},{"location":"tutorials/jenkins/parallel-robot-pipeline/#configure-the-pipeline","title":"Configure the pipeline","text":"<p>First, create a new pipeline via New Item button in the rigth side menu of the Jenkins dashboard. The name of the pipeline could be for example <code>Screenshots</code> and it should be an pipeline.</p> <p>In the configure pipeline view, scroll to the bottom and under Pipeline sub-header select <code>Pipeline script from SCM</code>. SCM type should be <code>Git</code> and Repository URL the url of this repository: <code>https://github.com/cicd-tutorials/cicd-tutorials.net.git</code>. Ensure that branch specifier includes <code>main</code> branch of the repository and modify the Script Path to be <code>docs/tutorials/jenkins/parallel-robot-pipeline/Jenkinsfile</code>.</p> <p>The pipeline executes the same Robot Framework suite twice: once with Firefox and once with Chromium. This is done in parallel. After the test suites have finished, the log files are combined in the next stage.</p> Jenkinsfile<pre><code>String d = \"docs/tutorials/jenkins/parallel-robot-pipeline\"\n\npipeline {\n    agent any\n    parameters {\n        string(\n            name: 'URL',\n            defaultValue: '',\n            description: 'Target URL for the Robot Framework tasks')\n    }\n    stages {\n        stage('Run tasks') {\n            parallel {\n                stage('Chromium') {\n                    agent { docker {\n                        image 'ghcr.io/cicd-tutorials/robot-browser:latest'\n                        args '--entrypoint=\"\"'\n                        reuseNode true\n                    } }\n                    steps {\n                        sh \"robot -d robot_output -l none -r none -o chromium.xml -N Chromium -v URL:${params.URL} --nostatusrc $d/suites/\"\n                        // If reuseNode true was not used, we would have to stash the output XML.\n                        // stash includes: 'robot_output/**', name: 'Chromium'\n                    }\n                }\n                stage('Firefox') {\n                    agent { docker {\n                        image 'ghcr.io/cicd-tutorials/robot-browser:latest'\n                        args '--entrypoint=\"\"'\n                        reuseNode true\n                    } }\n                    steps {\n                        sh \"robot -d robot_output -l none -r none -o b.xml -N Firefox -v URL:${params.URL} --nostatusrc $d/suites/\"\n                        // If reuseNode true was not used, we would have to stash the output XML.\n                        // stash includes: 'robot_output/**', name: 'Firefox'\n                    }\n                }\n            }\n        }\n        stage('Process logs') {\n            agent { docker {\n                image 'ghcr.io/cicd-tutorials/robot-browser:latest'\n                args '--entrypoint=\"\"'\n                reuseNode true\n            } }\n            steps {\n                // If reuseNode true was not used, we would have to unstash the output XMLs.\n                // unstash 'Chromium'\n                // unstash 'Firefox'\n                sh \"rebot -d rebot_output -o output.xml -N '${env.JOB_BASE_NAME} ${BUILD_DISPLAY_NAME}' --nostatusrc robot_output/*.xml\"\n            }\n        }\n    }\n    post {\n        success {\n            robot outputPath: 'rebot_output', otherFiles: '**/*.png', onlyCritical: false, passThreshold: 100.0, unstableThreshold: 0.0\n        }\n    }\n}\n</code></pre> <p>After you have created the pipeline, try to execute it by clicking Build Now. All Robot Framework tasks should be in Skipped state as we did not specify an URL variable. In addition, after the first execution Jenkins should have updated the project configuration to contain parameters defined in the pipeline and we can now pass target URL to our automation tasks in Build with Parameters menu.</p> <p>The Robot Framework suite defined in suites/screenshot.robot uses Browser library to take a screenshot of the page available in the URL defined with the URL variable.</p> suites/screenshot.robot<pre><code>*** Settings ***\nLibrary             OperatingSystem\nLibrary             Browser\nSuite Setup         Check URL and open browser\nSuite Teardown      Close browser\n\n*** Variables ***\n${BROWSER}          chromium\n${URL}              ${EMPTY}\n\n*** Tasks ***\nCapture Screenshot\n    Skip if  not $URL  msg=Target URL not specified\n    New Page  ${URL}\n    Take Screenshot  EMBED\n\n*** Keywords ***\nOpen browser defined by environment\n    ${browser}=  Get Environment Variable    BROWSER    ${BROWSER}\n    New Browser  ${browser}\n    New Context  viewport={'width': 1280, 'height': 720}\n\nCheck URL and open browser\n    Skip if  not $URL  msg=Target URL not specified\n    Open browser defined by environment\n</code></pre> <p>Finally, If the robot log cannot be loaded after task execution, see this stackoverflow post for solution. To summarize, run following command in Jenkins Script Console to modify Jenkins servers Content Security Policy (CSP):</p> <pre><code>System.setProperty(\"hudson.model.DirectoryBrowserSupport.CSP\",\"sandbox allow-scripts; default-src 'none'; img-src 'self' data: ; style-src 'self' 'unsafe-inline' data: ; script-src 'self' 'unsafe-inline' 'unsafe-eval' ;\")\n</code></pre>"},{"location":"tutorials/jenkins/parallel-robot-pipeline/#building-and-running-the-docker-container","title":"Building and running the Docker container","text":"<p>The Jenkins pipeline listed above uses container image from Github Container Registry to run the pipelines. The container image is created using Dockerfile defined by this tutorial.</p> Dockerfile<pre><code>FROM mcr.microsoft.com/playwright:v1.48.0-noble AS base\n\n# Disable interactive configuration\nENV DEBIAN_FRONTEND='noninteractive'\n\nWORKDIR /work\nCOPY ./entrypoint.sh ./requirements.txt /work/\nRUN apt-get update &amp;&amp; \\\n    apt-get install -y \\\n        python3-pip &amp;&amp; \\\n    pip install --break-system-packages -r requirements.txt &amp;&amp; \\\n    rfbrowser init &amp;&amp; \\\n    chmod +x entrypoint.sh\n\nENTRYPOINT [\"./entrypoint.sh\"]\n\n\nFROM base\n\nCOPY suites/ suites/\nCOPY --from=base /work/entrypoint.sh .\n</code></pre> <p>The Dockerfile is based on Playwright image that contains the Browser binaries and other Playwright related dependencies of the Browser library. In addition, the Dockerfile installs Python and Python libraries defined in requirements.txt to the container image.</p> requirements.txt<pre><code>robotframework&gt;=4\nrobotframework-browser&gt;=18\n</code></pre>"},{"location":"tutorials/jenkins/parallel-robot-pipeline/#running-the-tasks-locally","title":"Running the tasks locally","text":"<p>Build the Docker containers with <code>docker build</code>:</p> <pre><code>docker build . --tag rf-screenshot\n</code></pre> <p>Execute the Robot Framework suites with <code>docker run</code>:</p> <pre><code># Chromium\ndocker run --rm -v $(pwd)/out:/out -e BROWSER=chromium rf-screenshot -d /out -v URL:https://cicd-tutorials.net/\n\n# Firefox\ndocker run --rm -v $(pwd)/out:/out -e BROWSER=firefox rf-screenshot -d /out -v URL:https://cicd-tutorials.net/\n</code></pre>"},{"location":"tutorials/jenkins/sonarqube-jenkins/","title":"Integrating Jenkins and SonarQube","text":"<p>This tutorial uses the same Jenkins configuration as the Jenkins with access to hosts Docker engine tutorial. If you did any configuration in jenkins-host-docker directory, sync the project names with <code>-p</code>/<code>--project-name</code> option or <code>COMPOSE_PROJECT_NAME</code> environment variable to use the same volumes. For example:</p> <pre><code># Replace jenkins with jenkins-host-docker, if you used default project name in jenkins-host-docker directory.\n\n# With -p/--project-name argument:\ndocker compose -p jenkins up -d\n\n# With COMPOSE_PROJECT_NAME environment variable:\nexport COMPOSE_PROJECT_NAME=jenkins\ndocker compose up -d\n</code></pre> <p>In additions to <code>jenkins</code> service, we now define a <code>sonarqube</code> service as well in the docker-compose.yml:</p> docker-compose.yml<pre><code>version: \"3\"\nservices:\n  jenkins:\n    build: ../jenkins-host-docker/\n    ports:\n    # Web user interface\n    - 8080:8080\n    # Java agents\n    - 50000:50000\n    volumes:\n    # Persistent volume for the Jenkins data\n    - \"jenkins.data:/var/jenkins_home\"\n    # Host systems docker socket\n    - \"/var/run/docker.sock:/var/run/docker.sock\"\n  sonarqube:\n    image: sonarqube:community\n    ports:\n    # Web user interface\n    - 9000:9000\n    volumes:\n    - \"sonarqube.data:/opt/sonarqube/\"\n\nvolumes:\n  jenkins.data:\n  sonarqube.data:\n</code></pre>"},{"location":"tutorials/jenkins/sonarqube-jenkins/#gettings-started-with-sonarqube","title":"Gettings started with SonarQube","text":"<p>To get started with SonarQube, access the Web UI and login with <code>admin:admin</code> credentials. Create a access token in My account &gt; Security and store the token. Use this access token to authenticate to SonarQube from CI instead of the username and password combination.</p> <p>In order to test the SonarQube installation, run <code>sonar-scanner</code> in a code repository. This can be done, for example, by using the sonarsource/sonar-scanner-cli Docker image:</p> <pre><code># This command should be run in the repository root directory\ndocker run \\\n  --rm \\\n  --net host \\\n  -e SONAR_HOST_URL=\"http://localhost:9000\" \\\n  -v ${PWD}:/usr/src \\\n  sonarsource/sonar-scanner-cli \\\n  -D\"sonar.projectKey=$(basename ${PWD})\" \\\n  -D\"sonar.login=${your_sonar_access_token}\"\n</code></pre> <p>If this succeeds, you are ready to move this analysis into Jenkins.</p>"},{"location":"tutorials/jenkins/sonarqube-jenkins/#using-sonarqube-from-jenkins-pipeline","title":"Using SonarQube from Jenkins pipeline","text":"<p>First, install SonarQube Scanner plugin to your Jenkins instance through Manage Jenkins &gt; Manage plugins menu. Configure SonarQube instance to SonarQube servers section of the Manage Jenkins &gt; Configure System menu: Use <code>http://sonarqube:9000</code> as the server URL and create a secret text credential for the access token you stored earlier.</p> <p>After the SonarQube server is configured to Jenkins, sonar-scanner can be executed in a stage that uses the same sonarsource/sonar-scanner-cli Docker image that was used in the previous step as well. This can be done with a stage level Docker agent:</p> Jenkinsfile<pre><code>pipeline {\n  agent any\n  stages {\n    stage('Checkout') {\n      steps {\n        git \"${GIT_URL}\"\n      }\n    }\n    stage('Analyze') {\n      agent {\n        docker {\n          image 'sonarsource/sonar-scanner-cli'\n          // In order to be able to use http://sonarqube:9000 we need to be in the same network as Jenkins and SonarQube are in.\n          args  '--net jenkins_default'\n          // To quarantee that the workspace contains the sources pulled in previous stage, we need to use the pipeline level workspace.\n          reuseNode true\n        }\n      }\n      steps {\n        // The parameter must match the name you gave for the SonarQube server when configuring it.\n        withSonarQubeEnv('Sonar') {\n          // Here, job name is used as the project key and current workspace as the sources location.\n          sh \"sonar-scanner -D'sonar.projectKey=${JOB_NAME}' -D'sonar.sources=${WORKSPACE}'\"\n        }\n      }\n    }\n  }\n}\n</code></pre> <p>See Jenkinsfile for a example of a complete pipeline. If you try to execute this example pipeline replace <code>${GIT_URL}</code> with the URL to your git repository of choice.</p> <p>After the pipeline with sonar-scanner run has been executed, the job view in Jenkins should include the SonarQube quality gate status of the linked Sonar Project. Note that in this demo setup these links will not work as the Jenkins uses the <code>http://sonarqube:9000</code> URL for the SonarQube server which is likely not accessible from your browser. To see the projects in SonarQube, replace <code>http://sonarqube:9000</code> with <code>http://localhost:9000</code> in the URL.</p> <p>Alternative for using <code>http://sonarqube:9000</code> or <code>http://localhost:9000</code> as the SonarQube URL would be to use your host machines local IP: <code>http://${HOST_IP}:9000</code>. On linux systems, you can find your local IP with <code>hostname -I</code> command. On Windows systems, you can find your local by looking for IP address from the output of <code>ipconfig</code> command. You only need to configure this to the Manage Jenkins &gt; Configure System menu. When using local host IP, you can omit the network argument from docker agent block and the links from the job view should work as is.</p> <p>Note that this setup should only be used for development. For anything production like, configure SonarQube to use database such as postgres, do not use root or admin credentials, and setup the Jenkins and SonarQube to a suitable private network. See also Jenkins and SonarQube documentation for production usage instructions.</p>"}]}